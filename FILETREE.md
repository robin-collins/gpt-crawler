# Project File Tree Structure

This document provides a comprehensive overview of the gpt-crawler project file structure, updated to reflect all current files and directories.

## Root Directory Structure

```
gpt-crawler/
â”œâ”€â”€ ARCHITECTURE.md                     # System architecture documentation
â”œâ”€â”€ CHANGELOG.md                       # Project change log and version history
â”œâ”€â”€ cursor-extensions.txt              # Cursor IDE extensions configuration
â”œâ”€â”€ Dockerfile                         # Docker container configuration
â”œâ”€â”€ eslint.config.js                   # ESLint configuration for code linting
â”œâ”€â”€ example.scrape-config.ts           # Example scraping configuration template
â”œâ”€â”€ extracted_code.json               # Extracted code analysis results
â”œâ”€â”€ FILETREE.md                        # This file - project structure documentation
â”œâ”€â”€ License                            # Project license file
â”œâ”€â”€ package-lock.json                  # NPM dependency lock file
â”œâ”€â”€ package.json                       # NPM package configuration and dependencies
â”œâ”€â”€ README.md                          # Main project documentation
â”œâ”€â”€ scrape-config.ts                   # Main scraping configuration
â”œâ”€â”€ swagger.js                         # Swagger API documentation configuration
â”œâ”€â”€ tsconfig.json                      # TypeScript compiler configuration
â”œâ”€â”€ tsting-scrape-config.ts           # Testing scraping configuration
â”œâ”€â”€ yarn.lock                          # Yarn dependency lock file
â”œâ”€â”€ containerapp/                      # Container application deployment files
â”‚   â”œâ”€â”€ Dockerfile                     # Container-specific Dockerfile
â”‚   â”œâ”€â”€ README.md                      # Container deployment documentation
â”‚   â”œâ”€â”€ run.sh                         # Container startup script
â”‚   â”œâ”€â”€ scrape-config.ts              # Container scraping configuration
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ init.sh                    # Data initialization script
â”‚       â””â”€â”€ scrape-config.ts          # Data-specific scraping configuration
â”œâ”€â”€ crawled/                           # Directory for crawled content output
â”œâ”€â”€ docs/                              # Project documentation directory
â”œâ”€â”€ example_html/                      # Example HTML files for testing
â”œâ”€â”€ example_html2/                     # Additional example HTML files
â”œâ”€â”€ old_crawled/                       # Archived crawled content
â”œâ”€â”€ reporting/                         # Reporting and analytics files
â”œâ”€â”€ save_output/                       # Saved output files and results
â”‚   â”œâ”€â”€ cleaned_page_content.html      # Cleaned HTML content
â”‚   â”œâ”€â”€ DataFormat.md                  # Data format documentation
â”‚   â”œâ”€â”€ full_page_screenshot.png       # Full page screenshot
â”‚   â”œâ”€â”€ initial_page_content.html      # Original page content
â”‚   â””â”€â”€ initial_page_content copy.html # Backup of original content
â”œâ”€â”€ src/                               # Source code directory
â”‚   â”œâ”€â”€ backup-crawler-output.ts       # Backup functionality for crawler output
â”‚   â”œâ”€â”€ cli.ts                         # Command-line interface implementation
â”‚   â”œâ”€â”€ config.ts                      # Configuration management
â”‚   â”œâ”€â”€ core.ts                        # Core crawling functionality
â”‚   â”œâ”€â”€ main.ts                        # Main application entry point
â”‚   â”œâ”€â”€ markdownHelpers.ts             # Markdown processing utilities
â”‚   â”œâ”€â”€ server.ts                      # Web server implementation
â”‚   â”œâ”€â”€ test-code-cleaning.ts          # Code cleaning test utilities
â”‚   â”œâ”€â”€ test-extract-code.ts           # Code extraction test utilities
â”‚   â”œâ”€â”€ test-json-extract.ts           # JSON extraction test utilities
â”‚   â”œâ”€â”€ test-url-cleaning.ts           # URL cleaning test utilities
â”‚   â””â”€â”€ visitPageHelpers.ts            # Page visiting helper functions
â””â”€â”€ storage/                           # Storage directory for persistent data
```

## External Configuration Files

### Global Custom Modes Configuration
```
c:\Users\Robin\AppData\Roaming\Cursor\User\globalStorage\rooveterinaryinc.roo-cline\settings\custom_modes.yaml
```

This file contains custom mode configurations including the newly added "ğŸŒğŸ’¼ Job Researcher" mode for job market research and company analysis.

## Key File Categories

### Configuration Files
- `package.json` - Node.js project dependencies and scripts
- `tsconfig.json` - TypeScript compilation settings
- `eslint.config.js` - Code quality and style rules
- `Dockerfile` - Container deployment configuration
- `scrape-config.ts` - Main crawling configuration

### Source Code
- `src/` - All TypeScript source files
- `src/main.ts` - Application entry point
- `src/core.ts` - Core crawling logic
- `src/server.ts` - Web server functionality

### Documentation
- `README.md` - Primary project documentation
- `ARCHITECTURE.md` - Technical architecture details
- `CHANGELOG.md` - Version history and changes
- `FILETREE.md` - This file structure documentation

### Output and Data
- `crawled/` - Crawled content storage
- `save_output/` - Processed output files
- `storage/` - Persistent data storage
- `reporting/` - Analytics and reporting data

### Testing and Examples
- `example.scrape-config.ts` - Configuration templates
- `example_html/` - Test HTML content
- `src/test-*.ts` - Test utility files

## Recent Changes

- Added comprehensive project structure documentation
- Integrated "ğŸŒğŸ’¼ Job Researcher" custom mode for employment research
- Enhanced documentation with architectural details

---

*Last Updated: 2025-01-07*
*Version: 1.5.6*